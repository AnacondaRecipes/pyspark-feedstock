{% set name = "pyspark" %}
{% set version = "2.4.1" %}

package:
  name: "{{ name|lower }}"
  version: "{{ version }}"

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
  sha256: 923cc4075d586074f68b722f5ed029b0d25396828441b5ed421a0e40fe14e749
  patches:
    - 0001-Disable-symlinks-on-Windows.patch

build:
  noarch: python
  number: 0
  script: "{{ PYTHON }} -m pip install . --no-deps --ignore-installed -vv "

requirements:
  host:
    - pip
    - pypandoc
    - python
    - setuptools
  run:
    - numpy >=1.7
    - pandas >=0.19.2
    - py4j ==0.10.7
    - python

test:
  commands:
    - bash -c "compgen -c spark && compgen -c pyspark"  # [not win]
    - where *spark*                                     # [win]
  imports:
    - pyspark
    - pyspark.ml
    - pyspark.ml.linalg
    - pyspark.ml.param
    - pyspark.mllib
    - pyspark.mllib.linalg
    - pyspark.mllib.stat
    - pyspark.sql
    - pyspark.streaming

about:
  home: http://spark.apache.org/
  license: Apache 2.0
  # Not yet available in the pypi release
  license_file: '{{ environ["RECIPE_DIR"] }}/LICENSE.txt'
  summary: 'Apache Spark'
  description: Apache Spark is a fast and general engine for large-scale data processing.

extra:
  recipe-maintainers:
    - parente
    - ericdill
    - quasiben
    - dbast
    - mariusvniekerk
